<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Gaze Estimation Demo</title>
    <script src="gaze-estimation.js"></script>
    <style>
        #video,
        #canvas {
            box-sizing: content-box;
            width: 480px;
            height: 360px;
        }

        #video,
        #canvas {
            border: 5px solid black;
        }

        #canvas.valid {
            border-color: green;
        }

        #canvas.invalid {
            border-color: red;
        }

        .pos {
            width: 240px;
            height: 180px;
        }
    </style>
</head>

<body>
    <h1>Gaze Estimation Demo</h1>
    <p>Allow camera access to start gaze estimation.</p>
    <p id="status">Loading...</p>
    <p id="fps"></p>
    <div style="display: flex">
        <video id="video" autoplay playsinline></video>
        <canvas id="canvas"></canvas>
    </div>
    <div>
        <button id="topLeft" class="angle-button">左上</button>
        <button id="topRight" class="angle-button">右上</button>
    </div>
    <div>
        <button id="bottomLeft" class="angle-button">左下</button>
        <button id="bottomRight" class="angle-button">右下</button>
    </div>
    <div>
        <canvas class="pos" data-for="topLeft"></canvas>
        <canvas class="pos" data-for="topRight"></canvas>
    </div>
    <div>
        <canvas class="pos" data-for="bottomLeft"></canvas>
        <canvas class="pos" data-for="bottomRight"></canvas>
    </div>
    <script>

        if (document.readyState === "loading") {
            // Loading hasn't finished yet
            document.addEventListener("DOMContentLoaded", startGazeEstimator);
        } else {
            // `DOMContentLoaded` has already fired
            startGazeEstimator();
        }

        function startGazeEstimator() {
            document.getElementById('status').innerText = 'model読み込み中...';

            const video = document.getElementById('video');
            const canvas = document.getElementById('canvas');
            const ctx = canvas.getContext('2d');
            async function processVideoFrame(canvas) {
                const ctx = canvas.getContext('2d');
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
                const { estimateImage, gazePitch, gazeYaw, isOutOfBounds } = await GazeEstimator.estimate(canvas, canvas);
                if (estimateImage) {
                    //ctx.putImageData(estimateImage, 0, 0);
                }

                return { estimateImage, gazePitch, gazeYaw, isOutOfBounds }
            }

            async function startGazeEstimation() {
                // Request camera access
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                video.srcObject = stream;

                video.addEventListener('loadeddata', async () => {
                    await GazeEstimator.init('./resnet18.onnx');
                    document.getElementById('status').innerText = 'model読み込み完了';
                    async function estimateGaze() {
                        const { estimateImage, gazePitch, gazeYaw, isOutOfBounds } = await processVideoFrame(canvas);
                        if (isOutOfBounds != null) {
                            if (isOutOfBounds) {
                                canvas.classList.add('invalid');
                                canvas.classList.remove('valid');
                            } else {
                                canvas.classList.add('valid');
                                canvas.classList.remove('invalid');
                            }
                        } else {
                            canvas.classList.remove('valid');
                            canvas.classList.remove('invalid');
                        }

                        // Update the FPS display
                        const now = performance.now();
                        if (!window.lastFrameTime) {
                            window.lastFrameTime = now;
                            window.frameCount = 0;
                        }
                        window.frameCount++;
                        const elapsed = now - window.lastFrameTime;
                        if (elapsed >= 1000) {
                            const fps = (window.frameCount / (elapsed / 1000)).toFixed(2);
                            document.getElementById('fps').innerText = `FPS: ${fps}`;
                            window.lastFrameTime = now;
                            window.frameCount = 0;
                        }

                        // Call this function repeatedly
                        requestAnimationFrame(estimateGaze);
                    }

                    estimateGaze();
                });
            }

            startGazeEstimation().catch(err => {
                // console.error('Error starting gaze estimation:', err);
            });

            const borders = {};
            document.querySelectorAll('.angle-button').forEach(button => {
                const canvas = document.querySelector(`canvas[data-for="${button.id}"]`);
                const ctx = canvas.getContext('2d');
                button.addEventListener('click', async (e) => {
                    const { estimateImage, gazePitch, gazeYaw } = await processVideoFrame(canvas);
                    if (estimateImage) {
                        GazeEstimator.setRectPoint(button.id, {
                            pitch: gazePitch,
                            yaw: gazeYaw
                        });
                    }
                });
            });
        }
    </script>
</body>

</html>